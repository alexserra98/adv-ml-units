{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lab 1: **Kernels** and **features**\n",
                "\n",
                "Advanced Topics in Machine Learning -- Spring 2023, UniTS\n",
                "\n",
                "<a target=\"_blank\" href=\"https://colab.research.google.com/github/ganselmif/adv-ml-units/blob/main/notebooks/AdvML_UniTS_2023_Lab_01_Intro_to_Kernels.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Empirical verification of the *Kernel* $\\leftrightarrow$ *feature expansion* equivalence\n",
                "\n",
                "Recall the definition of *kernel*:\n",
                "> Let $\\mathcal{X}$ be a non-empty set. A function $k: \\mathcal{X} \\times \\mathcal{X} \\rightarrow \\mathbb{R}$ is called a *kernel* if there exists a real-Hilbert space $\\mathcal{H}$ and a map $\\phi: \\mathcal{X} \\rightarrow \\mathcal{H}$ such that $\\forall x, x^\\prime \\in \\mathcal{X}$, $k(x, x^\\prime) := \\langle \\phi(x) , \\phi(x^\\prime) \\rangle_{\\mathcal{H}}$.\n",
                "\n",
                "To motivate the usefulness of kernelized ML methods, we can show that -- for $x\\in\\mathbb{R}^{d \\in \\mathbb{N}}$ -- the computation of $k(x, x^\\prime)$ in kernel form is equivalent to the explicit scalar product $\\langle \\varphi(x) , \\varphi(x^\\prime) \\rangle = \\varphi(x)^{T} \\varphi(x^\\prime)$ of some corresponding expanded feature maps $\\varphi: {R}^{d} \\rightarrow \\mathbb{R}^{d^\\prime}$ with generally $d^\\prime \\gg d$ (or even *infinite-dimensional* $\\varphi$s), though significantly simpler and more efficient to compute.\n",
                "\n",
                "In the lab that follows, verify such equivalence for simple kernels: the non-uniform *quadratic* (in $\\mathbb{R}^{d}$) and the *Gaussian* (in $\\mathbb{R}$).\n",
                "\n",
                "For each kernel:\n",
                "\n",
                "1. Implement a function that computes the kernel between two arrays of coordinates;\n",
                "2. Derive the explicit feature map $\\varphi(x)$ corresponding to that kernel;\n",
                "3. Implement a function that computes such feature map for a given array of coordinates;\n",
                "4. Verify that the kernel computed by (1) and the scalar product of its arguments through (3) are indeed equivalent.\n",
                "\n",
                "**Hint**: in case of need, you can finitely approximate the feature map by Taylor expansion.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 72,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import math"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {},
            "outputs": [],
            "source": [
                "def nu_quadratic_kernel(x, x_prime):\n",
                "    \"\"\"Compute the quadratic kernel between two arrays of coordinates.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    x : array-like, shape (n_features)\n",
                "        First array of coordinates.\n",
                "    x_prime : array-like, shape (n_features)\n",
                "        Second array of coordinates.\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    k : array-like, shape (1)\n",
                "        Kernel value.\n",
                "    \"\"\"\n",
                "    ret = torch.dot(x, x_prime)+torch.tensor(1.0)\n",
                "    return ret ** 2\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor(1089.)"
                        ]
                    },
                    "execution_count": 65,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "nu_quadratic_kernel(torch.tensor([1, 2, 3]), torch.tensor([4, 5, 6]))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "metadata": {},
            "outputs": [],
            "source": [
                "def nu_quadratic_feature_map(x):\n",
                "    \"\"\"Compute the feature map corresponding to the quadratic kernel.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    x : array-like, shape (n_features)\n",
                "        Array of coordinates.\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    phi_x : array-like, shape (n_features)\n",
                "        Feature map.\n",
                "    \"\"\"\n",
                "    d = len(x)\n",
                "    x = x.flip(0)\n",
                "    list_map = [e**2 for e in x]\n",
                "    c = torch.sqrt(torch.tensor(2))\n",
                "    for i in range(d):\n",
                "        for j in range(i+1,d):\n",
                "            list_map.append(c*x[i]*x[j])\n",
                "    list_map.extend([c*e for e in x])\n",
                "\n",
                "    \n",
                "    return torch.tensor(list_map)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor(1089.)\n",
                        "tensor(1088.)\n"
                    ]
                }
            ],
            "source": [
                "# Check that the two functions are equivalent on a randomly-initialized array\n",
                "x = torch.tensor([1, 2, 3])\n",
                "y = torch.tensor([4, 5, 6])\n",
                "print(nu_quadratic_kernel(x, y))\n",
                "print(torch.dot(nu_quadratic_feature_map(x),nu_quadratic_feature_map(y)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 246,
            "metadata": {},
            "outputs": [],
            "source": [
                "def gaussian_kernel(x, x_prime, sigma):\n",
                "    \"\"\"Compute the Gaussian kernel between two arrays of coordinates.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    x : array-like, shape (n_features)\n",
                "        First array of coordinates.\n",
                "    x_prime : array-like, shape (n_features)\n",
                "        Second array of coordinates.\n",
                "    sigma : float\n",
                "        Kernel standard deviation.\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    k : array-like, shape (1)\n",
                "        Kernel value.\n",
                "    \"\"\"\n",
                "    v =  x-x_prime\n",
                "    v = torch.sum(v**2)\n",
                "    \n",
                "    return torch.exp(-v/(2*sigma**2))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 262,
            "metadata": {},
            "outputs": [],
            "source": [
                "def gaussian_feature_map(x, sigma, order):\n",
                "    \"\"\"Compute the feature map corresponding to the Gaussian kernel.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    x : array-like, shape (n_features)\n",
                "        Array of coordinates.\n",
                "    sigma : float\n",
                "        Kernel standard deviation.\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    phi_x : array-like, shape (n_features)\n",
                "        Feature map.\n",
                "    \"\"\"\n",
                "    first_factor = torch.exp(-torch.dot(x.transpose(-1,0),x)/(2*sigma**2))\n",
                "    ret = torch.stack([((x/torch.sqrt(torch.tensor(sigma)))**i/torch.sqrt(torch.tensor(math.factorial(i)))) for i in range(0,order)])\n",
                "    ret *= first_factor\n",
                "    return ret.flatten()\n",
                "    \n",
                "    \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 263,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor(0.0012)\n",
                        "tensor(1.8709e-12)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_1044/2888552204.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
                        "  ret = torch.stack([((x/torch.sqrt(torch.tensor(sigma)))**i/torch.sqrt(torch.tensor(math.factorial(i)))) for i in range(0,order)])\n"
                    ]
                }
            ],
            "source": [
                "x = torch.tensor([1, 2, 3])\n",
                "y = torch.tensor([4, 5, 6])\n",
                "c = torch.sqrt(torch.tensor(2))\n",
                "print(gaussian_kernel(x, y, c))\n",
                "print(torch.dot(gaussian_feature_map(x, c, 20), gaussian_feature_map(y, 1, 20)))\n"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "authorship_tag": "ABX9TyPkibvpTEMRILBn2/x8IuJj",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
